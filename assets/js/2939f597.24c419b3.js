"use strict";(self.webpackChunkskyrimnet_docs=self.webpackChunkskyrimnet_docs||[]).push([[479],{6686:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"Large Language Models/openrouter","title":"OpenRouter","description":"SkyrimNet \u2013 Understanding LLMs for Roleplay","source":"@site/docs/Large Language Models/OpenRouter.md","sourceDirName":"Large Language Models","slug":"/Large Language Models/openrouter","permalink":"/SkyrimNet-GamePlugin/Large Language Models/openrouter","draft":false,"unlisted":false,"editUrl":"https://github.com/goncalo22/SkyrimNet-GamePlugin/edit/main/docs/Large Language Models/OpenRouter.md","tags":[],"version":"current","frontMatter":{"id":"openrouter","title":"OpenRouter","displayed_sidebar":"tutorialSidebar"},"sidebar":"tutorialSidebar","previous":{"title":"Model Agents","permalink":"/SkyrimNet-GamePlugin/Large Language Models/model-agents"},"next":{"title":"Suggested LLMs","permalink":"/SkyrimNet-GamePlugin/Large Language Models/suggested-llms"}}');var s=t(4848),r=t(8453);const o={id:"openrouter",title:"OpenRouter",displayed_sidebar:"tutorialSidebar"},a=void 0,l={},d=[{value:"SkyrimNet \u2013 Understanding LLMs for Roleplay",id:"skyrimnet--understanding-llms-for-roleplay",level:2},{value:"1. What is an LLM?",id:"1-what-is-an-llm",level:3},{value:"2. Key LLM Settings",id:"2-key-llm-settings",level:3},{value:"Tokens",id:"tokens",level:4},{value:"Context Size",id:"context-size",level:4},{value:"Temperature",id:"temperature",level:4},{value:"Repetition Penalty",id:"repetition-penalty",level:4},{value:"Top-P (Nucleus Sampling)",id:"top-p-nucleus-sampling",level:4},{value:"Frequency Penalty",id:"frequency-penalty",level:4},{value:"3. Roleplay Tuning Tips",id:"3-roleplay-tuning-tips",level:3},{value:"4. Why This Matters in SkyrimNet",id:"4-why-this-matters-in-skyrimnet",level:3}];function c(e){const n={br:"br",h2:"h2",h3:"h3",h4:"h4",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)("p",{align:"center",children:(0,s.jsx)("img",{src:"/SkyrimNet-GamePlugin/img/construction.png",alt:"construction",width:"400"})}),"\n",(0,s.jsx)(n.h2,{id:"skyrimnet--understanding-llms-for-roleplay",children:"SkyrimNet \u2013 Understanding LLMs for Roleplay"}),"\n",(0,s.jsx)(n.h3,{id:"1-what-is-an-llm",children:"1. What is an LLM?"}),"\n",(0,s.jsxs)(n.p,{children:["A Large Language Model (LLM) is an AI system trained on vast amounts of text to generate natural language based on a prompt.",(0,s.jsx)(n.br,{}),"\n","In SkyrimNet, the LLM acts like an improvisational actor \u2014 it reads game context, NPC memory, and triggers, then \u201cperforms\u201d dialogue, narration, or actions that feel believable in Skyrim\u2019s world."]}),"\n",(0,s.jsxs)(n.p,{children:["Think of the LLM as ",(0,s.jsx)(n.strong,{children:"the brain"})," of your AI characters, with SkyrimNet as the ",(0,s.jsx)(n.strong,{children:"nervous system"})," that feeds it information and acts on its decisions."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"2-key-llm-settings",children:"2. Key LLM Settings"}),"\n",(0,s.jsx)(n.h4,{id:"tokens",children:"Tokens"}),"\n",(0,s.jsx)(n.p,{children:"Tokens are small chunks of text, usually a few characters long. LLMs have a maximum token limit, which is split between the input (prompt) and the output (response). Long conversations, NPC histories, and game event logs all need to fit into this limit, or older information will be dropped."}),"\n",(0,s.jsx)(n.h4,{id:"context-size",children:"Context Size"}),"\n",(0,s.jsx)(n.p,{children:"The amount of conversation and history the LLM can \u201csee\u201d at one time. Larger context sizes let the model remember more backstory, relationship history, and past events in a scene without forgetting earlier details."}),"\n",(0,s.jsx)(n.h4,{id:"temperature",children:"Temperature"}),"\n",(0,s.jsxs)(n.p,{children:["Controls how creative or predictable the AI is.",(0,s.jsx)(n.br,{}),"\n","Lower values (0.1\u20130.3) make it precise and focused, while higher values (0.8\u20131.2) make it more unpredictable and creative. Mid-range values often produce natural, human-like conversation."]}),"\n",(0,s.jsx)(n.h4,{id:"repetition-penalty",children:"Repetition Penalty"}),"\n",(0,s.jsx)(n.p,{children:"Discourages the model from repeating itself. A moderate penalty keeps dialogue varied without sounding forced. Too little penalty can cause looping speech; too much can make phrasing awkward."}),"\n",(0,s.jsx)(n.h4,{id:"top-p-nucleus-sampling",children:"Top-P (Nucleus Sampling)"}),"\n",(0,s.jsx)(n.p,{children:"Instead of pure randomness, Top-P limits the possible next words to those that make the most sense in the moment. Lower values keep the model more focused, higher values allow more variation."}),"\n",(0,s.jsx)(n.h4,{id:"frequency-penalty",children:"Frequency Penalty"}),"\n",(0,s.jsx)(n.p,{children:"Prevents the AI from overusing the same words or phrases too often, helping to avoid repetitive sentence structures and keeping the conversation fresh."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"3-roleplay-tuning-tips",children:"3. Roleplay Tuning Tips"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Aim for immersion:"})," Use mid-range temperatures so NPCs feel lively without becoming nonsensical."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Keep important NPCs in view:"})," Large context sizes preserve backstories and relationship histories during long play sessions."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Be clear with actions:"})," Lower temperature for gameplay-critical actions like combat decisions or quest triggers."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Add personality variety:"})," Adjust temperature and Top-P slightly for different NPCs to give them distinct speaking styles."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Avoid conversation loops:"})," Use repetition and frequency penalties together to keep dialogue progressing naturally."]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"4-why-this-matters-in-skyrimnet",children:"4. Why This Matters in SkyrimNet"}),"\n",(0,s.jsx)(n.p,{children:"These settings directly affect:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["How ",(0,s.jsx)(n.strong,{children:"consistent"})," NPCs are with their established personalities."]}),"\n",(0,s.jsxs)(n.li,{children:["How ",(0,s.jsx)(n.strong,{children:"immersive"})," roleplay feels over extended sessions."]}),"\n",(0,s.jsxs)(n.li,{children:["How well the AI balances ",(0,s.jsx)(n.strong,{children:"creativity"})," and ",(0,s.jsx)(n.strong,{children:"control"})," when driving dialogue, narration, and in-game actions."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Think of tuning LLM parameters like tuning an instrument \u2014 the same model can produce a bard\u2019s ballad, a drunken tavern story, or a formal court decree, depending on how you set it up."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var i=t(6540);const s={},r=i.createContext(s);function o(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);